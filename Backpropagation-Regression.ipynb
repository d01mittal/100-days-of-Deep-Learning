{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63dc9a73-e232-4b9e-bb37-e0b53ea1dfa6",
   "metadata": {},
   "source": [
    "# Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3cbf94-dd50-42e2-aff8-0b04b4596a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc3a9d4-ea40-4500-ab89-5f7cf6a9895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]],columns=['cgpa','profile_score','lpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0f9954-ee17-447c-b610-9bea8bfb736b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  lpa\n",
       "0     8              8    4\n",
       "1     7              9    5\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52945e3-93d2-4114-a7a7-095c65d53ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters={}\n",
    "    L=len(layer_dims)\n",
    "\n",
    "    for l in range(1,L):\n",
    "        parameters['W'+str(l)]=np.ones((layer_dims[l-1],layer_dims[l]))*0.1\n",
    "        parameters['b'+str(l)]=np.zeros((layer_dims[l],1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15290233-a755-4402-b72e-34322f9b23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev,W,b):\n",
    "    Z=np.dot(W.T, A_prev)+b\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ce9df2-25e2-42fb-85e8-d3910cf07a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Prop\n",
    "def L_layer_forward(X, parameters):\n",
    "\n",
    "  A = X\n",
    "  L = len(parameters) // 2                  # number of layers in the neural network\n",
    "  \n",
    "  for l in range(1, L+1):\n",
    "    A_prev = A \n",
    "    Wl = parameters['W' + str(l)]\n",
    "    bl = parameters['b' + str(l)]\n",
    "    print(\"A\"+str(l-1)+\": \", A_prev)\n",
    "    print(\"W\"+str(l)+\": \", Wl)\n",
    "    print(\"b\"+str(l)+\": \", bl)\n",
    "    print(\"--\"*20)\n",
    "\n",
    "    A = linear_forward(A_prev, Wl, bl)\n",
    "    print(\"A\"+str(l)+\": \", A)\n",
    "    print(\"**\"*20)\n",
    "          \n",
    "  return A,A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77363f69-1a1e-4e4b-93bb-ae8b6ede01c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "****************************************\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32]]\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[0][0]\n",
    "\n",
    "# Parameter initialization\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04e30c9-0b3d-42b9-b23c-b7170b69ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_hat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "502036fa-ec40-4df3-935b-112c33fff135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6],\n",
       "       [1.6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3122b21c-0b36-4816-9112-524408bb5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n",
    "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n",
    "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n",
    "\n",
    "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af492e67-f2d7-4252-bff1-0ab6fa72d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_parameters(parameters,y,y_hat,A1,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c093c1c-99e3-442f-8409-041a7fc51b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10658137, 0.10658137],\n",
       "        [0.10658137, 0.10658137]]),\n",
       " 'b1': array([[0.00082267],\n",
       "        [0.00082267]]),\n",
       " 'W2': array([[0.111776],\n",
       "        [0.111776]]),\n",
       " 'b2': array([[0.119136]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2e3c96-765c-4967-82d0-0054ced3b839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.10658137 0.10658137]\n",
      " [0.10658137 0.10658137]]\n",
      "b1:  [[0.00082267]\n",
      " [0.00082267]]\n",
      "----------------------------------------\n",
      "A1:  [[1.81270598]\n",
      " [1.81270598]]\n",
      "****************************************\n",
      "A1:  [[1.81270598]\n",
      " [1.81270598]]\n",
      "W2:  [[0.111776]\n",
      " [0.111776]]\n",
      "b2:  [[0.119136]]\n",
      "----------------------------------------\n",
      "A2:  [[0.52437005]]\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[3].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[3][0]\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52d26f85-086a-4ddf-83fe-92c71e414d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "****************************************\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.10658137 0.10658137]\n",
      " [0.10658137 0.10658137]]\n",
      "b1:  [[0.00082267]\n",
      " [0.00082267]]\n",
      "----------------------------------------\n",
      "A1:  [[1.70612461]\n",
      " [1.70612461]]\n",
      "****************************************\n",
      "A1:  [[1.70612461]\n",
      " [1.70612461]]\n",
      "W2:  [[0.111776]\n",
      " [0.111776]]\n",
      "b2:  [[0.119136]]\n",
      "----------------------------------------\n",
      "A2:  [[0.50054357]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.11458955 0.1168776 ]\n",
      " [0.11458955 0.1168776 ]]\n",
      "b1:  [[0.0019667]\n",
      " [0.0019667]]\n",
      "----------------------------------------\n",
      "A1:  [[1.83539945]\n",
      " [1.87200826]]\n",
      "****************************************\n",
      "A1:  [[1.83539945]\n",
      " [1.87200826]]\n",
      "W2:  [[0.12712927]\n",
      " [0.12712927]]\n",
      "b2:  [[0.13612818]]\n",
      "----------------------------------------\n",
      "A2:  [[0.6074482]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.12409711 0.13272353]\n",
      " [0.12412266 0.13276611]]\n",
      "b1:  [[0.00355129]\n",
      " [0.00355555]]\n",
      "----------------------------------------\n",
      "A1:  [[2.11350869]\n",
      " [2.26036654]]\n",
      "****************************************\n",
      "A1:  [[2.11350869]\n",
      " [2.26036654]]\n",
      "W2:  [[0.14692424]\n",
      " [0.14731907]]\n",
      "b2:  [[0.15810417]]\n",
      "----------------------------------------\n",
      "A2:  [[0.80162493]]\n",
      "****************************************\n",
      "Epoch -  1 Loss -  25.321744156025517\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.13482804 0.15847776]\n",
      " [0.1349909  0.15884991]]\n",
      "b1:  [[0.00569748]\n",
      " [0.0057292 ]]\n",
      "----------------------------------------\n",
      "A1:  [[2.16424899]\n",
      " [2.54435052]]\n",
      "****************************************\n",
      "A1:  [[2.16424899]\n",
      " [2.54435052]]\n",
      "W2:  [[0.17312488]\n",
      " [0.17534027]]\n",
      "b2:  [[0.18773702]]\n",
      "----------------------------------------\n",
      "A2:  [[1.00854947]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.1437341  0.16738383]\n",
      " [0.14411185 0.16797086]]\n",
      "b1:  [[0.00681073]\n",
      " [0.00686932]]\n",
      "----------------------------------------\n",
      "A1:  [[2.30995614]\n",
      " [2.69029382]]\n",
      "****************************************\n",
      "A1:  [[2.30995614]\n",
      " [2.69029382]]\n",
      "W2:  [[0.18607337]\n",
      " [0.19056287]]\n",
      "b2:  [[0.19654577]]\n",
      "----------------------------------------\n",
      "A2:  [[1.13903718]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.15475619 0.18155508]\n",
      " [0.15553536 0.18265822]]\n",
      "b1:  [[0.00838532]\n",
      " [0.00850125]]\n",
      "----------------------------------------\n",
      "A1:  [[2.49227603]\n",
      " [2.92441391]]\n",
      "****************************************\n",
      "A1:  [[2.49227603]\n",
      " [2.92441391]]\n",
      "W2:  [[0.20391068]\n",
      " [0.21133712]]\n",
      "b2:  [[0.21905904]]\n",
      "----------------------------------------\n",
      "A2:  [[1.34529793]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.16744187 0.20269788]\n",
      " [0.16886056 0.20486689]]\n",
      "b1:  [[0.0104996 ]\n",
      " [0.01072211]]\n",
      "----------------------------------------\n",
      "A1:  [[2.87403566]\n",
      " [3.48261418]]\n",
      "****************************************\n",
      "A1:  [[2.87403566]\n",
      " [3.48261418]]\n",
      "W2:  [[0.22711228]\n",
      " [0.23856167]]\n",
      "b2:  [[0.24787107]]\n",
      "----------------------------------------\n",
      "A2:  [[1.73141811]]\n",
      "****************************************\n",
      "Epoch -  2 Loss -  18.320004165722047\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.18100301 0.23524462]\n",
      " [0.18336278 0.23967222]]\n",
      "b1:  [[0.01321183]\n",
      " [0.01362256]]\n",
      "----------------------------------------\n",
      "A1:  [[2.92813816]\n",
      " [3.8129573 ]]\n",
      "****************************************\n",
      "A1:  [[2.92813816]\n",
      " [3.8129573 ]]\n",
      "W2:  [[0.25739647]\n",
      " [0.27525854]]\n",
      "b2:  [[0.28579571]]\n",
      "----------------------------------------\n",
      "A2:  [[2.08903719]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.18921518 0.24345679]\n",
      " [0.1922245  0.24853394]]\n",
      "b1:  [[0.01423835]\n",
      " [0.01473027]]\n",
      "----------------------------------------\n",
      "A1:  [[3.06876509]\n",
      " [3.95573325]]\n",
      "****************************************\n",
      "A1:  [[3.06876509]\n",
      " [3.95573325]]\n",
      "W2:  [[0.26858759]\n",
      " [0.28983138]]\n",
      "b2:  [[0.29365331]]\n",
      "----------------------------------------\n",
      "A2:  [[2.26438116]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.20014476 0.25750911]\n",
      " [0.20415354 0.26387128]]\n",
      "b1:  [[0.01579972]\n",
      " [0.01643442]]\n",
      "----------------------------------------\n",
      "A1:  [[3.25820367]\n",
      " [4.20020184]]\n",
      "****************************************\n",
      "A1:  [[3.25820367]\n",
      " [4.20020184]]\n",
      "W2:  [[0.28537753]\n",
      " [0.31147414]]\n",
      "b2:  [[0.31694538]]\n",
      "----------------------------------------\n",
      "A2:  [[2.55501776]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.21287024 0.27871824]\n",
      " [0.21822616 0.28732564]]\n",
      "b1:  [[0.01792063]\n",
      " [0.01877986]]\n",
      "----------------------------------------\n",
      "A1:  [[3.7009857 ]\n",
      " [4.86027872]]\n",
      "****************************************\n",
      "A1:  [[3.7009857 ]\n",
      " [4.86027872]]\n",
      "W2:  [[0.30782644]\n",
      " [0.34041338]]\n",
      "b2:  [[0.34730334]]\n",
      "----------------------------------------\n",
      "A2:  [[3.14106851]]\n",
      "****************************************\n",
      "Epoch -  3 Loss -  9.473661050729628\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.22585131 0.3098728 ]\n",
      " [0.23281    0.32232686]]\n",
      "b1:  [[0.02051684]\n",
      " [0.02169662]]\n",
      "----------------------------------------\n",
      "A1:  [[3.68980727]\n",
      " [5.07929387]]\n",
      "****************************************\n",
      "A1:  [[3.68980727]\n",
      " [5.07929387]]\n",
      "W2:  [[0.33639014]\n",
      " [0.37792434]]\n",
      "b2:  [[0.38564221]]\n",
      "----------------------------------------\n",
      "A2:  [[3.54644581]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.22831673 0.31233823]\n",
      " [0.23558598 0.32510284]]\n",
      "b1:  [[0.02082502]\n",
      " [0.02204362]]\n",
      "----------------------------------------\n",
      "A1:  [[3.73931597]\n",
      " [5.13433676]]\n",
      "****************************************\n",
      "A1:  [[3.73931597]\n",
      " [5.13433676]]\n",
      "W2:  [[0.3397372 ]\n",
      " [0.38253181]]\n",
      "b2:  [[0.38343892]]\n",
      "----------------------------------------\n",
      "A2:  [[3.61787081]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.23509059 0.32104747]\n",
      " [0.24326252 0.33497268]]\n",
      "b1:  [[0.02179271]\n",
      " [0.02314027]]\n",
      "----------------------------------------\n",
      "A1:  [[3.86496148]\n",
      " [5.2991519 ]]\n",
      "****************************************\n",
      "A1:  [[3.86496148]\n",
      " [5.2991519 ]]\n",
      "W2:  [[0.35007363]\n",
      " [0.39672445]]\n",
      "b2:  [[0.39948871]]\n",
      "----------------------------------------\n",
      "A2:  [[3.85481293]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.24452913 0.33677838]\n",
      " [0.25406036 0.35296907]]\n",
      "b1:  [[0.02336581]\n",
      " [0.02493991]]\n",
      "----------------------------------------\n",
      "A1:  [[4.29473577]\n",
      " [5.94446068]]\n",
      "****************************************\n",
      "A1:  [[4.29473577]\n",
      " [5.94446068]]\n",
      "W2:  [[0.36665576]\n",
      " [0.41945979]]\n",
      "b2:  [[0.42375017]]\n",
      "----------------------------------------\n",
      "A2:  [[4.49190204]]\n",
      "****************************************\n",
      "Epoch -  4 Loss -  3.2520938634031613\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.25426555 0.36014576]\n",
      " [0.2653287  0.38001309]]\n",
      "b1:  [[0.02531309]\n",
      " [0.02719358]]\n",
      "----------------------------------------\n",
      "A1:  [[4.18206705]\n",
      " [5.94846444]]\n",
      "****************************************\n",
      "A1:  [[4.18206705]\n",
      " [5.94846444]]\n",
      "W2:  [[0.388199  ]\n",
      " [0.44927837]]\n",
      "b2:  [[0.45429457]]\n",
      "----------------------------------------\n",
      "A2:  [[4.75028523]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.24968072 0.35556094]\n",
      " [0.26004246 0.37472686]]\n",
      "b1:  [[0.02473998]\n",
      " [0.0265328 ]]\n",
      "----------------------------------------\n",
      "A1:  [[4.11288719]\n",
      " [5.88800108]]\n",
      "****************************************\n",
      "A1:  [[4.11288719]\n",
      " [5.88800108]]\n",
      "W2:  [[0.38192351]\n",
      " [0.44035228]]\n",
      "b2:  [[0.43885171]]\n",
      "----------------------------------------\n",
      "A2:  [[4.60245475]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.25182457 0.35831731]\n",
      " [0.26251936 0.37791144]]\n",
      "b1:  [[0.02504625]\n",
      " [0.02688664]]\n",
      "----------------------------------------\n",
      "A1:  [[4.16118723]\n",
      " [5.95590488]]\n",
      "****************************************\n",
      "A1:  [[4.16118723]\n",
      " [5.95590488]]\n",
      "W2:  [[0.38519363]\n",
      " [0.44503378]]\n",
      "b2:  [[0.44582887]]\n",
      "----------------------------------------\n",
      "A2:  [[4.69927052]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.25800593 0.36861958]\n",
      " [0.26970762 0.38989188]]\n",
      "b1:  [[0.02607647]\n",
      " [0.02808469]]\n",
      "----------------------------------------\n",
      "A1:  [[4.55259758]\n",
      " [6.54988512]]\n",
      "****************************************\n",
      "A1:  [[4.55259758]\n",
      " [6.54988512]]\n",
      "W2:  [[0.39601879]\n",
      " [0.46052782]]\n",
      "b2:  [[0.46312928]]\n",
      "----------------------------------------\n",
      "A2:  [[5.28244776]]\n",
      "****************************************\n",
      "Epoch -  5 Loss -  1.3407132589299962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.26507636, 0.38558861],\n",
       "        [0.27800387, 0.40980287]]),\n",
       " 'b1': array([[0.02749056],\n",
       "        [0.02974394]]),\n",
       " 'W2': array([[0.41165744],\n",
       "        [0.48302736]]),\n",
       " 'b2': array([[0.48646246]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs implementation\n",
    "\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  Loss = []\n",
    "\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "    y = df[['lpa']].values[j][0]\n",
    "\n",
    "    # Parameter initialization\n",
    "\n",
    "\n",
    "    y_hat,A1 = L_layer_forward(X,parameters)\n",
    "    y_hat = y_hat[0][0]\n",
    "\n",
    "    update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "    Loss.append((y-y_hat)**2)\n",
    "\n",
    "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf45250-4008-4971-8003-c2cda33ab879",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b328eaa7-42fe-4db3-8120-ac8b11e980d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b6023e-f0fe-4731-bf4f-ad3815b5f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]],columns=['cgpa','profile_score','lpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34962c6e-3965-4ef3-a2f3-bfd7ab39b55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  lpa\n",
       "0     8              8    4\n",
       "1     7              9    5\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d72980e-0998-4848-99b8-7dc6522f5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "454f8e36-25ad-487b-b138-30702f836067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(2,activation='linear',input_dim=2))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eb2df4d-b279-474e-8961-1d432cccfe5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m6\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m3\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b008e1cb-6787-49aa-a1a1-0c5622d81fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.92284   , -1.1506337 ],\n",
       "        [ 0.00541461, -1.0060177 ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[ 0.96538126],\n",
       "        [-0.62915903]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39a57285-38bb-4158-bcca-92fb682ff350",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights=[np.array([[0.1,0.1],\n",
    "                      [0.1,0.1]],dtype=np.float32),\n",
    "            np.array([0.,0.],dtype=np.float32),\n",
    "            np.array([[0.1],\n",
    "                     [0.1]],dtype=np.float32),\n",
    "            np.array([0.],dtype=np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99b12a84-a0c3-4db5-8ebc-016844f5b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60920c1c-bb4f-492c-ab11-c06cbb3af8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c95684c-955b-4ebc-a0fc-3fe481079c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0ad31f2-0975-4113-bb12-d4cdd15c0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 22.9302\n",
      "Epoch 2/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.6442 \n",
      "Epoch 3/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.0178 \n",
      "Epoch 4/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 24.0185  \n",
      "Epoch 5/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.7356 \n",
      "Epoch 6/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.7913 \n",
      "Epoch 7/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.5892 \n",
      "Epoch 8/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.3104 \n",
      "Epoch 9/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4126 \n",
      "Epoch 10/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.6198 \n",
      "Epoch 11/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.1686 \n",
      "Epoch 12/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2944 \n",
      "Epoch 13/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.9646 \n",
      "Epoch 14/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.6558 \n",
      "Epoch 15/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.0957 \n",
      "Epoch 16/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4807\n",
      "Epoch 17/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6000 \n",
      "Epoch 18/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.8555 \n",
      "Epoch 19/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.5423\n",
      "Epoch 20/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2600\n",
      "Epoch 21/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2073\n",
      "Epoch 22/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.1096\n",
      "Epoch 23/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.6477 \n",
      "Epoch 24/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.1790 \n",
      "Epoch 25/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.6072 \n",
      "Epoch 26/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.4377\n",
      "Epoch 27/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.8644\n",
      "Epoch 28/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.2157 \n",
      "Epoch 29/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13.3677\n",
      "Epoch 30/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.4688\n",
      "Epoch 31/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.0492 \n",
      "Epoch 32/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.3876\n",
      "Epoch 33/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4198  \n",
      "Epoch 34/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.2787  \n",
      "Epoch 35/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.5710 \n",
      "Epoch 36/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.0915 \n",
      "Epoch 37/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3408 \n",
      "Epoch 38/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8643 \n",
      "Epoch 39/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.7249 \n",
      "Epoch 40/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.2336\n",
      "Epoch 41/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.2858  \n",
      "Epoch 42/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6326 \n",
      "Epoch 43/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5325 \n",
      "Epoch 44/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7897 \n",
      "Epoch 45/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4859 \n",
      "Epoch 46/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.8381 \n",
      "Epoch 47/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9025 \n",
      "Epoch 48/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8794  \n",
      "Epoch 49/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2191 \n",
      "Epoch 50/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2974  \n",
      "Epoch 51/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8825  \n",
      "Epoch 52/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4716   \n",
      "Epoch 53/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2215 \n",
      "Epoch 54/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3866 \n",
      "Epoch 55/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0982  \n",
      "Epoch 56/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8573 \n",
      "Epoch 57/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1610 \n",
      "Epoch 58/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5083 \n",
      "Epoch 59/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8346 \n",
      "Epoch 60/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9677     \n",
      "Epoch 61/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0603 \n",
      "Epoch 62/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4342 \n",
      "Epoch 63/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3993 \n",
      "Epoch 64/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9362 \n",
      "Epoch 65/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1931 \n",
      "Epoch 66/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3933  \n",
      "Epoch 67/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8790 \n",
      "Epoch 68/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9286 \n",
      "Epoch 69/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4713 \n",
      "Epoch 70/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8789 \n",
      "Epoch 71/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2194 \n",
      "Epoch 72/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7053 \n",
      "Epoch 73/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1080 \n",
      "Epoch 74/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3065  \n",
      "Epoch 75/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7983 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fa7e74fe30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df.iloc[:,0:-1].values,df['lpa'].values,epochs=75,verbose=1,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6986bce-7fe1-4577-b18b-7a923964b5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.37378705, 0.37378705],\n",
       "        [0.36589873, 0.36589873]], dtype=float32),\n",
       " array([0.27256554, 0.27256554], dtype=float32),\n",
       " array([[0.37317467],\n",
       "        [0.37317467]], dtype=float32),\n",
       " array([0.20498255], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
